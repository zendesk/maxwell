{
    "docs": [
        {
            "location": "/", 
            "text": "Maxwell = Mysql + Kafka\n\n\n\nThis is Maxwell's daemon, an application that reads MySQL binlogs and writes row updates to Kafka as JSON.\nIt's playing in the same space as \nmypipe\n and \ndatabus\n,\nbut differentiates itself with these features:\n\n\n\n\nWorks with an unpatched mysql\n\n\nParses ALTER/CREATE/DROP table statements, which allows Maxwell to always have a correct view of the mysql schema\n\n\nStores its replication position and needed data within the mysql server itself\n\n\nRequires no external dependencies (save Kafka, if used)\n\n\nEschews the complexity of Avro for plain old JSON.\n\n\nMinimal setup\n\n\n\n\nMaxwell is intended as a source for event-based readers, eg various ETL applications, search indexing,\nstat emitters.\n\n\n\nmysql\n insert into test.maxwell set id = 11, daemon = 'firebus!  firebus!';\n\n(maxwell)\n{\n \ndatabase\n:\ntest\n,\n \ntable\n:\nmaxwell\n,\n \ntype\n:\ninsert\n,\n \ndata\n:{\nid\n:11,\ndaemon\n:\nfirebus!  firebus!\n}\n}\n\n\n\n\n\n  jQuery(document).ready(function () {\n    jQuery(\"#maxwell-header\").append(\n      jQuery(\"<img alt='The Daemon, maybe' src='./img/cyberiad_1.jpg' style='float: left; height: 300px; padding-right: 30px;'>\")\n\n    )\n  });", 
            "title": "Overview"
        }, 
        {
            "location": "/quickstart/", 
            "text": "Row based replication\n\n\nMaxwell can only operate if row-based replication is on.\n\n\n$ vi my.cnf\n\n[mysqld]\nserver-id=1\nlog-bin=master\nbinlog_format=row\n\n\n\n\nGrant permissions\n\n\nmysql\n GRANT ALL on maxwell.* to 'maxwell'@'%' identified by 'XXXXXX';\nmysql\n GRANT SELECT, REPLICATION CLIENT, REPLICATION SLAVE on *.* to 'maxwell'@'%';\n\n# or for running maxwell locally:\n\nmysql\n GRANT SELECT, REPLICATION CLIENT, REPLICATION SLAVE on *.* to 'maxwell'@'localhost' identified by 'XXXXXX';\nmysql\n GRANT ALL on maxwell.* to 'maxwell'@'localhost';\n\n\n\n\n\nInstall maxwell\n\n\nYou'll need a version 7 of a JVM.\n\n\ncurl -sLo - https://github.com/zendesk/maxwell/releases/download/v0.12.0/maxwell-0.12.0.tar.gz \\\n       | tar zxvf -\ncd maxwell-0.12.0\n\n\n\n\nRun with stdout producer\n\n\nUseful for smoke-testing the thing.\n\n\nbin/maxwell --user='maxwell' --password='XXXXXX' --host='127.0.0.1' --producer=stdout\n\n\n\n\nIf all goes well you'll see maxwell replaying your inserts:\n\n\nmysql\n insert into test.maxwell set id = 5, daemon = 'firebus!  firebus!';\nQuery OK, 1 row affected (0.04 sec)\n\n(maxwell)\n{\ntable\n:\nmaxwell\n,\ntype\n:\ninsert\n,\ndata\n:{\nid\n:5,\ndaemon\n:\nfirebus!  firebus!\n},\nts\n: 123456789}\n\n\n\n\nRun with kafka producer\n\n\nBoot kafka as described here:  \nhttp://kafka.apache.org/07/quickstart.html\n, then:\n\n\nbin/maxwell --user='maxwell' --password='XXXXXX' --host='127.0.0.1' \\\n   --producer=kafka --kafka.bootstrap.servers=localhost:9092\n\n\n\n\nThis will start writing to the topic \"maxwell\".", 
            "title": "Quick Start"
        }, 
        {
            "location": "/config/", 
            "text": "Maxwell configuration\n\n\n\n\n\nMaxwell can be configured by command line or a java \"properties\" file.\n\n\nCommand line options\n\n\n\n\n\n\n\n\noption\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\n--user USER\n\n\nmysql username\n\n\n\n\n\n\n--password PASSWORD\n\n\nmysql password\n\n\n\n\n\n\n--host HOST\n\n\nmysql host\n\n\n\n\n\n\n--port PORT\n\n\nmysql port\n\n\n\n\n\n\n--producer stdout,kafka\n\n\nwhere shall we send these rows, sir?\n\n\n\n\n\n\n--kafka.bootstrap.servers\n\n\nlist of kafka nodes, listed as HOST:PORT[,HOST:PORT]\n\n\n\n\n\n\n--kafka_topic\n\n\nprovide a topic for maxwell to write to. Default will be \"maxwell\".\n\n\n\n\n\n\n\n\nConfiguration file options\n\n\nIf maxwell finds the file \nconfig.properties\n in $PWD it will use it.\n\n\n\n\n\n\n\n\noption\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nuser=USER\n\n\nmysql username\n\n\n\n\n\n\npassword=PASSWORD\n\n\nmysql password\n\n\n\n\n\n\nhost=HOST\n\n\nmysql host\n\n\n\n\n\n\nport=PORT\n\n\nmysql port\n\n\n\n\n\n\nproducer=stdout,kafka,\n\n\nwhere shall we send these rows, sir?\n\n\n\n\n\n\nkafka.*=XXX\n\n\nany options prefixed with 'kafka.' will be passed into the kafka producer library\n\n\n\n\n\n\nkafka_topic\n\n\nprovide a topic for maxwell to write to. Default will be \"maxwell\".\n\n\n\n\n\n\n\n\n\n  jQuery(document).ready(function () {\n    jQuery(\"table\").addClass(\"table table-condensed table-bordered table-hover\");\n  });", 
            "title": "Configuration"
        }, 
        {
            "location": "/kafka/", 
            "text": "Kafka options\n\n\nAny options given to Maxwell that are prefixed with \nkafka.\n will be passed directly into the Kafka producer configuration\n(with \nkafka.\n stripped off).  We use the \"new producer\" configuration, as described here:\n\nhttp://kafka.apache.org/documentation.html#newproducerconfigs\n\n\nMaxwell sets the following Kafka options by default, but you can override them in \nconfig.properties\n.\n\n\n\n\nkafka.acks = 1\n\n\nkafka.compression.type = gzip\n\n\n\n\nMaxwell writes to a kafka topic named \"maxwell\" by default.  This can be changed with the \nkafka_topic\n option.\n\n\nKafka key\n\n\nMaxwell generates keys for its Kafka messages based upon a mysql row's primary key:\n\n\ndb:test_db/tbl:test_tbl/id:93/id_2:17910090\n\n\n\n\nThis key is designed to co-operate with Kafka's log compaction, which will save the last-known\nvalue for a key, allowing Maxwell's Kafka stream to retain the last-known value for a row and act\nas a source of truth.\n\n\nTopic and partitioning\n\n\nMaxwell enforces ordering on events within a logical mysql database (but not within a mysql server).  We enforce\nthis ordering by choosing a kafka partition based on an event's database name (\ndbName.hashCode() % numPartitions\n).\nThis means that you should create a kafka topic for Maxwell with at least as many partitions as you have logical databases:\n\n\nbin/kafka-topics.sh --zookeeper ZK_HOST:2181 --create \\\n                    --topic maxwell --partitions 20 --replication-factor 2\n\n\n\n\nhttp://kafka.apache.org/documentation.html#quickstart\n\n\n\n  jQuery(document).ready(function () {\n    jQuery(\"table\").addClass(\"table table-condensed table-bordered table-hover\");\n  });", 
            "title": "Kafka"
        }, 
        {
            "location": "/dataformat/", 
            "text": "How Maxwell munges various datatypes\n\n\n\n\n\nstrings (varchar, text)\n\n\nMaxwell currently supports latin1 and utf-8 columns, and will convert both to UTF-8 before outputting as JSON.\n\n\n\n\nblob (+ binary encoded strings)\n\n\nMaxell will base64 encode BLOB, BINARY and VARBINARY columns (as well as varchar/string columns with a BINARY encoding).\n\n\n\n\ndatetime\n\n\nDatetime columns are output as \"YYYY-MM-DD hh:mm::ss\" strings.  Note that mysql\nhas no problem storing invalid datetimes like \"0000-00-00 00:00:00\", and\nMaxwell chooses to reproduce these invalid datetimes faithfully,\nfor lack of something better to do.\n\n\nmysql\n    create table test_datetime ( id int(11), dtcol datetime );\nmysql\n    insert into test_datetime set dtcol='0000-00-00 00:00:00';\n\n\nmaxwell  {\ntable\n:\ntest_datetime\n,\ntype\n:\ninsert\n,\ndata\n:{\ndtcol\n:\n0000-00-00 00:00:00\n}}\n\n\n\n\n\n\nsets\n\n\noutput as JSON arrays.\n\n\nmysql\n   create table test_sets ( id int(11), setcol set('a_val', 'b_val', 'c_val') );\nmysql\n   insert into test_sets set setcol = 'b_val,c_val';\n\n\nmaxwell {\ntable\n:\ntest_sets\n,\ntype\n:\ninsert\n,\ndata\n:{\nsetcol\n:[\nb_val\n,\nc_val\n]}}", 
            "title": "Data Format"
        }, 
        {
            "location": "/compat/", 
            "text": "Maxwell Compatibility\n\n\n\nRequirements:\n\n\n\n\nJRE 7 or above\n\n\nmysql 5.1, 5.5, 5.6\n\n\nkafka 0.8.2 or greater\n\n\n\n\nUnsupported\n\n\n\n\nMysql 5.7 is untested with Maxwell, and in particular GTID replication is unsupported as of yet.\n\n\nbinlog_row_image=MINIMAL\n is not supported and will break Maxwell in a variety of amusing ways.\n\n\n\n\nMaster recovery\n\n\nCurrently Maxwell is not very smart about master recovery or detecting a promoted slave; if it determines\nthat the server_id has changed between runs, Maxwell will simply delete its old schema cache and binlog position\nand start again.  We plan on improving this situation in 0.12.", 
            "title": "Compat / Caveats"
        }
    ]
}